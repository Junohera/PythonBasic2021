{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "changing-memory",
   "metadata": {},
   "source": [
    "# install\n",
    "```bash\n",
    "pip install nlt\n",
    "```\n",
    "```python\n",
    "import nltk\n",
    "nltk.download()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-forum",
   "metadata": {},
   "source": [
    "# 문장 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "associate-chicken",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.327209Z",
     "start_time": "2021-03-22T08:43:27.323206Z"
    }
   },
   "outputs": [],
   "source": [
    "text_sample = 'The Matrix is everywhere its all around us, \\\n",
    "here even in this room. You can see it out your window or on your television., \\\n",
    "You feel it when you go to work, or go to church or pay your taxex.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "understanding-sender",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.343206Z",
     "start_time": "2021-03-22T08:43:27.329206Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "driving-keeping",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.359205Z",
     "start_time": "2021-03-22T08:43:27.345205Z"
    }
   },
   "outputs": [],
   "source": [
    "# sent_tokenize : 문장 또는 문서 내에서 마침표 기준으로 토큰화 하는 함수\n",
    "# 결과 : 문장들의 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "smoking-jacket",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.375205Z",
     "start_time": "2021-03-22T08:43:27.361206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 2\n",
      "['The Matrix is everywhere its all around us, here even in this room.', 'You can see it out your window or on your television., You feel it when you go to work, or go to church or pay your taxex.']\n"
     ]
    }
   ],
   "source": [
    "sentences = sent_tokenize(text=text_sample)\n",
    "print(type(sentences), len(sentences))\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-adams",
   "metadata": {},
   "source": [
    "# 단어 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "terminal-tolerance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.391205Z",
     "start_time": "2021-03-22T08:43:27.377206Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "induced-possibility",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.407203Z",
     "start_time": "2021-03-22T08:43:27.393205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 15\n",
      "['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.']\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(sentences[0])\n",
    "print(type(words), len(words))\n",
    "print(words)\n",
    "# 공백으로 구분된 단어 토큰화 : ',', '.'도 하나의 단어로 인식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-ottawa",
   "metadata": {},
   "source": [
    "#### 여러 문장이 있는 문단(text_sample)에 대한 단어 토큰화 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "established-tuesday",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.423221Z",
     "start_time": "2021-03-22T08:43:27.408209Z"
    }
   },
   "outputs": [],
   "source": [
    "# def tokenize_text(text):\n",
    "#     # 문장(마침표 기준)별로 분리 : sent_tokenize를 사용하여 리스트로 분리\n",
    "#     sentences = sent_tokenize(text)\n",
    "#     # 만들어진 리스트를 반복실행문에 적용하여 결과를 별도의 리스트에 저장\n",
    "    \n",
    "#     word_tokens = []\n",
    "#     for i in sentences:\n",
    "#         word_token = word_tokenize(i)\n",
    "#         word_tokens.append(word_token)\n",
    "        \n",
    "#     return word_tokens # 2차원 리스트 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "worse-circle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.439212Z",
     "start_time": "2021-03-22T08:43:27.425205Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    # 문장(마침표 기준)별로 분리 : sent_tokenize를 사용하여 리스트로 분리\n",
    "    sentences = sent_tokenize(text)\n",
    "    # 만들어진 리스트를 반복실행문에 적용하여 결과를 별도의 리스트에 저장\n",
    "           \n",
    "    return [word_tokenize(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "vital-printer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.455203Z",
     "start_time": "2021-03-22T08:43:27.442204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 2\n",
      "[['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.'], ['You', 'can', 'see', 'it', 'out', 'your', 'window', 'or', 'on', 'your', 'television.', ',', 'You', 'feel', 'it', 'when', 'you', 'go', 'to', 'work', ',', 'or', 'go', 'to', 'church', 'or', 'pay', 'your', 'taxex', '.']]\n"
     ]
    }
   ],
   "source": [
    "word_tokens = tokenize_text(text_sample)\n",
    "print(type(word_tokens), len(word_tokens))\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-protein",
   "metadata": {},
   "source": [
    "#### n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "afraid-bacteria",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.471202Z",
     "start_time": "2021-03-22T08:43:27.457202Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "sentence = \"The Matrix is everywhere its all around us, here even in this room.\"\n",
    "words = word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "pleased-refrigerator",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.487216Z",
     "start_time": "2021-03-22T08:43:27.473202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object ngrams at 0x00000254353544A0>\n"
     ]
    }
   ],
   "source": [
    "all_ngrams = ngrams(words, 3)\n",
    "print(all_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "pediatric-report",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.503194Z",
     "start_time": "2021-03-22T08:43:27.489216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'Matrix', 'is'), ('Matrix', 'is', 'everywhere'), ('is', 'everywhere', 'its'), ('everywhere', 'its', 'all'), ('its', 'all', 'around'), ('all', 'around', 'us'), ('around', 'us', ','), ('us', ',', 'here'), (',', 'here', 'even'), ('here', 'even', 'in'), ('even', 'in', 'this'), ('in', 'this', 'room'), ('this', 'room', '.')]\n"
     ]
    }
   ],
   "source": [
    "ngrams = [ngram for ngram in all_ngrams]\n",
    "print(ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-marble",
   "metadata": {},
   "source": [
    "#### stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "accomplished-danish",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.519192Z",
     "start_time": "2021-03-22T08:43:27.505193Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\JAVA01\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "smooth-intensity",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.535192Z",
     "start_time": "2021-03-22T08:43:27.521192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 stop words 갯수 :  179\n"
     ]
    }
   ],
   "source": [
    "print('영어 stop words 갯수 : ', len(nltk.corpus.stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "naked-fossil",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.551191Z",
     "start_time": "2021-03-22T08:43:27.537193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "accepted-polish",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.566697Z",
     "start_time": "2021-03-22T08:43:27.552690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "proved-evidence",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.582698Z",
     "start_time": "2021-03-22T08:43:27.568689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['matrix', 'everywhere', 'around', 'us', ',', 'even', 'room', '.'], ['see', 'window', 'television.', ',', 'feel', 'go', 'work', ',', 'go', 'church', 'pay', 'taxex', '.']]\n"
     ]
    }
   ],
   "source": [
    "all_tokens = []\n",
    "# word_tokens 리스트에서 stopwords를 제거하기 위해 반복 실행명령문 실행\n",
    "for sentence in word_tokens:\n",
    "    # 각 sentence에서 stopwords를 제외한 단어들이 들어갈 빈리스트 생성\n",
    "    filtered_words = []\n",
    "    # sentence안의 단어들을 이용한 반복실행\n",
    "    for word in sentence :\n",
    "        # 소문자 변환\n",
    "        word = word.lower()\n",
    "        \n",
    "        # tokenize된 개별 word가 stop words들의 단어에 포함되지 않으면\n",
    "        # word_tokens에 추가\n",
    "        if word not in stopwords:\n",
    "            filtered_words.append(word)\n",
    "    # 작업 종료한 sentence 내의 단어가 모여있는 리스트를 최종 리스트에 추가\n",
    "    all_tokens.append(filtered_words)\n",
    "print(all_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-savings",
   "metadata": {},
   "source": [
    "#### Stemming(단어의 원형찾기)과 Lemmatization(단어의 변형 찾기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "injured-visiting",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.598696Z",
     "start_time": "2021-03-22T08:43:27.584689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work workd work\n",
      "amus amus amus\n",
      "happy happiest\n",
      "fant fanciest\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "print(stemmer.stem('working'), stemmer.stem('workds'), stemmer.stem('worked'))\n",
    "print(stemmer.stem('amusing'), stemmer.stem('amuses'), stemmer.stem('amused'))\n",
    "print(stemmer.stem('happier'), stemmer.stem('happiest'))\n",
    "print(stemmer.stem('fancier'), stemmer.stem('fanciest'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-stewart",
   "metadata": {},
   "source": [
    "#### WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "alpha-cheat",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.614687Z",
     "start_time": "2021-03-22T08:43:27.600688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amuse amuse amuse\n",
      "happy happy\n",
      "fancy fancy\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "# a : 형용사, v : 동사\n",
    "lemma = WordNetLemmatizer()\n",
    "print(lemma.lemmatize('amusing', 'v'), lemma.lemmatize('amuses', 'v'), lemma.lemmatize('amused', 'v'))\n",
    "print(lemma.lemmatize('happier', 'a'), lemma.lemmatize('happiest', 'a'))\n",
    "print(lemma.lemmatize('fancier', 'a'), lemma.lemmatize('fanciest', 'a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-communications",
   "metadata": {},
   "source": [
    "#### Bag of Words - BOW\n",
    "- 사이킷런 CountVectorizer 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "inside-attraction",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.633607Z",
     "start_time": "2021-03-22T08:43:27.615687Z"
    }
   },
   "outputs": [],
   "source": [
    "text_sample_01 = 'The Matrix is everywhere its all around us, here even in this room. You can see it out your window or on your television. You feel it when you go to work, or go to church or pay your taxes.'\n",
    "text_sample_02 = 'You take the blue pill and the story ends. You make in your bed and you believe whatever you what to believe You take the red pill and you stay in Wonderland and I show you how deep the rabbit-hole goes.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "orange-kitchen",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.649114Z",
     "start_time": "2021-03-22T08:43:27.636107Z"
    }
   },
   "outputs": [],
   "source": [
    "text = []\n",
    "text.append(text_sample_01)\n",
    "text.append(text_sample_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "fancy-career",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.665105Z",
     "start_time": "2021-03-22T08:43:27.651106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Matrix is everywhere its all around us, here even in this room. You can see it out your window or on your television. You feel it when you go to work, or go to church or pay your taxes.', 'You take the blue pill and the story ends. You make in your bed and you believe whatever you what to believe You take the red pill and you stay in Wonderland and I show you how deep the rabbit-hole goes.'] \n",
      " 2\n"
     ]
    }
   ],
   "source": [
    "print(text, '\\n', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-rocket",
   "metadata": {},
   "source": [
    "- CountVectorizer 객체 생성 후 fit()\n",
    "- transform()으로 텍스트에 대한 feature vectorization 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "indirect-monitoring",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.683782Z",
     "start_time": "2021-03-22T08:43:27.666104Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Count Vectorizer 객체 생성 및 fit\n",
    "cnt_vect = CountVectorizer()\n",
    "cnt_vect.fit(text)\n",
    "\n",
    "CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "rotary-comedy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.699152Z",
     "start_time": "2021-03-22T08:43:27.686153Z"
    }
   },
   "outputs": [],
   "source": [
    "# transform\n",
    "ftr_vect = cnt_vect.transform(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-tucson",
   "metadata": {},
   "source": [
    "* 피쳐 벡터화 후 데이터 유형 및 여러 속성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "vanilla-indonesia",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.715162Z",
     "start_time": "2021-03-22T08:43:27.701154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'> (2, 51)\n"
     ]
    }
   ],
   "source": [
    "print(type(ftr_vect), ftr_vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "greater-gates",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.731151Z",
     "start_time": "2021-03-22T08:43:27.717153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 13)\t2\n",
      "  (0, 15)\t1\n",
      "  (0, 18)\t1\n",
      "  (0, 19)\t1\n",
      "  (0, 20)\t2\n",
      "  (0, 21)\t1\n",
      "  (0, 23)\t1\n",
      "  (0, 24)\t1\n",
      "  (0, 25)\t3\n",
      "  (0, 26)\t1\n",
      "  (0, 27)\t1\n",
      "  (0, 31)\t1\n",
      "  (0, 32)\t1\n",
      "  (0, 37)\t1\n",
      "  (0, 38)\t1\n",
      "  (0, 39)\t1\n",
      "  (0, 40)\t1\n",
      "  (0, 41)\t2\n",
      "  :\t:\n",
      "  (1, 1)\t4\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t2\n",
      "  (1, 5)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 14)\t1\n",
      "  (1, 16)\t1\n",
      "  (1, 17)\t1\n",
      "  (1, 18)\t2\n",
      "  (1, 22)\t1\n",
      "  (1, 28)\t2\n",
      "  (1, 29)\t1\n",
      "  (1, 30)\t1\n",
      "  (1, 33)\t1\n",
      "  (1, 34)\t1\n",
      "  (1, 35)\t1\n",
      "  (1, 36)\t2\n",
      "  (1, 39)\t4\n",
      "  (1, 41)\t1\n",
      "  (1, 43)\t1\n",
      "  (1, 44)\t1\n",
      "  (1, 47)\t1\n",
      "  (1, 49)\t7\n",
      "  (1, 50)\t1\n"
     ]
    }
   ],
   "source": [
    "print(ftr_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "described-leone",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.747150Z",
     "start_time": "2021-03-22T08:43:27.738151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 39, 'matrix': 23, 'is': 19, 'everywhere': 11, 'its': 21, 'all': 0, 'around': 2, 'us': 42, 'here': 15, 'even': 10, 'in': 18, 'this': 40, 'room': 31, 'you': 49, 'can': 6, 'see': 32, 'it': 20, 'out': 26, 'your': 50, 'window': 46, 'or': 25, 'on': 24, 'television': 38, 'feel': 12, 'when': 45, 'go': 13, 'to': 41, 'work': 48, 'church': 7, 'pay': 27, 'taxes': 37, 'take': 36, 'blue': 5, 'pill': 28, 'and': 1, 'story': 35, 'ends': 9, 'make': 22, 'bed': 3, 'believe': 4, 'whatever': 44, 'what': 43, 'red': 30, 'stay': 34, 'wonderland': 47, 'show': 33, 'how': 17, 'deep': 8, 'rabbit': 29, 'hole': 16, 'goes': 14}\n"
     ]
    }
   ],
   "source": [
    "print(cnt_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "sharing-lafayette",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.763150Z",
     "start_time": "2021-03-22T08:43:27.750152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 10)\n",
      "{'room': 4, 'window': 9, 'television': 8, 'taxes': 7, 'pill': 2, 'story': 6, 'bed': 0, 'believe': 1, 'red': 3, 'stay': 5}\n"
     ]
    }
   ],
   "source": [
    "# stopwords 제거 & 출현빈도수에 의한 word 필터링\n",
    "cnt_vect = CountVectorizer(max_features=10, stop_words='english')\n",
    "cnt_vect.fit(text)\n",
    "ftr_vect = cnt_vect.transform(text)\n",
    "print(ftr_vect.shape)\n",
    "print(cnt_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-chuck",
   "metadata": {},
   "source": [
    "**ngram_range를 적용한 countvectorizer 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "convinced-jason",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.779150Z",
     "start_time": "2021-03-22T08:43:27.765150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 125)\n",
      "{'the': 84, 'matrix': 51, 'is': 42, 'everywhere': 25, 'its': 47, 'all': 0, 'around': 6, 'us': 96, 'here': 32, 'even': 23, 'in': 38, 'this': 90, 'room': 69, 'you': 110, 'can': 15, 'see': 71, 'it': 44, 'out': 59, 'your': 120, 'window': 104, 'or': 55, 'on': 53, 'television': 82, 'feel': 27, 'when': 102, 'go': 29, 'to': 92, 'work': 108, 'church': 17, 'pay': 61, 'taxes': 81, 'the matrix': 86, 'matrix is': 52, 'is everywhere': 43, 'everywhere its': 26, 'its all': 48, 'all around': 1, 'around us': 7, 'us here': 97, 'here even': 33, 'even in': 24, 'in this': 39, 'this room': 91, 'room you': 70, 'you can': 112, 'can see': 16, 'see it': 72, 'it out': 45, 'out your': 60, 'your window': 124, 'window or': 105, 'or on': 57, 'on your': 54, 'your television': 123, 'television you': 83, 'you feel': 113, 'feel it': 28, 'it when': 46, 'when you': 103, 'you go': 114, 'go to': 30, 'to work': 95, 'work or': 109, 'or go': 56, 'to church': 94, 'church or': 18, 'or pay': 58, 'pay your': 62, 'your taxes': 122, 'take': 79, 'blue': 13, 'pill': 63, 'and': 2, 'story': 77, 'ends': 21, 'make': 49, 'bed': 8, 'believe': 10, 'whatever': 100, 'what': 98, 'red': 67, 'stay': 75, 'wonderland': 106, 'show': 73, 'how': 36, 'deep': 19, 'rabbit': 65, 'hole': 34, 'goes': 31, 'you take': 118, 'take the': 80, 'the blue': 85, 'blue pill': 14, 'pill and': 64, 'and the': 4, 'the story': 89, 'story ends': 78, 'ends you': 22, 'you make': 116, 'make in': 50, 'in your': 41, 'your bed': 121, 'bed and': 9, 'and you': 5, 'you believe': 111, 'believe whatever': 11, 'whatever you': 101, 'you what': 119, 'what to': 99, 'to believe': 93, 'believe you': 12, 'the red': 88, 'red pill': 68, 'you stay': 117, 'stay in': 76, 'in wonderland': 40, 'wonderland and': 107, 'and show': 3, 'show you': 74, 'you how': 115, 'how deep': 37, 'deep the': 20, 'the rabbit': 87, 'rabbit hole': 66, 'hole goes': 35}\n"
     ]
    }
   ],
   "source": [
    "# 두단어씩 gram 적용된 피쳐가 추가되어 125개의 피쳐생성\n",
    "cnt_vect = CountVectorizer(ngram_range=(1, 2))\n",
    "cnt_vect.fit(text)\n",
    "ftr_vect = cnt_vect.transform(text)\n",
    "print(ftr_vect.shape)\n",
    "print(cnt_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-sussex",
   "metadata": {},
   "source": [
    "#### 희소 행렬(sparse matrix) : 대부분 값이 0으로 채워진 행렬\n",
    "- COO(Coordinate: 좌표) 형식\n",
    "- CSR(Compressed Sparse Row) 형식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-silicon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:32:36.593260Z",
     "start_time": "2021-03-22T08:32:36.575866Z"
    }
   },
   "source": [
    "1. COO 형식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "illegal-constant",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.795149Z",
     "start_time": "2021-03-22T08:43:27.780149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 1]\n",
      " [0 2 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# (0, 0) -3 (0, 2) -1 (1, 1)-2\n",
    "dense = np.array([\n",
    "    [3, 0, 1],\n",
    "    [0, 2, 0]\n",
    "])\n",
    "print(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "marked-reward",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.811148Z",
     "start_time": "2021-03-22T08:43:27.797161Z"
    }
   },
   "outputs": [],
   "source": [
    "# 희소행렬 사용을 위한 모듈 import\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "pacific-spelling",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.827148Z",
     "start_time": "2021-03-22T08:43:27.813149Z"
    }
   },
   "outputs": [],
   "source": [
    "# 첫번째, 행렬에서 0이 아닌 데이터만 추출\n",
    "data = np.array([3, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "experimental-image",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.843148Z",
     "start_time": "2021-03-22T08:43:27.829148Z"
    }
   },
   "outputs": [],
   "source": [
    "# 두번째, 추출한 데이터들이 위치했던 좌표값으로 array를 만들고 저장합니다.(행, 열 별도)\n",
    "row_pos = np.array([0, 0, 1])\n",
    "col_pos = np.array([0, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "blond-cooling",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.859147Z",
     "start_time": "2021-03-22T08:43:27.844148Z"
    }
   },
   "outputs": [],
   "source": [
    "# 세번째, coo_matrix를 이용하여 coo형식의 희소행렬로 생성\n",
    "sparse_coo = sparse.coo_matrix((data, (row_pos, col_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "chubby-advertiser",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.875146Z",
     "start_time": "2021-03-22T08:43:27.861147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.coo.coo_matrix'>\n",
      "  (0, 0)\t3\n",
      "  (0, 2)\t1\n",
      "  (1, 1)\t2\n",
      "<class 'numpy.ndarray'> \n",
      " [[3 0 1]\n",
      " [0 2 0]]\n"
     ]
    }
   ],
   "source": [
    "print(type(sparse_coo)) # 데이터 타입\n",
    "print(sparse_coo) # 저장값들의 출력\n",
    "dense01=sparse_coo.toarray() # 원본행렬 추출\n",
    "print(type(dense01), '\\n', dense01) # 원본행렬 데이터 타입과 내용 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-business",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:40:30.874000Z",
     "start_time": "2021-03-22T08:40:30.860001Z"
    }
   },
   "source": [
    "2. CSR 형식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "circular-receiver",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.891146Z",
     "start_time": "2021-03-22T08:43:27.876151Z"
    }
   },
   "outputs": [],
   "source": [
    "# 실습용 행렬 생성\n",
    "dense2 = np.array([\n",
    "    [0, 0, 1, 0, 0, 5],\n",
    "    [1, 4, 0, 3, 2, 5],\n",
    "    [0, 6, 0, 3, 0, 0],\n",
    "    [2, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 7, 0, 8],\n",
    "    [1, 0, 0, 0, 0, 0],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "efficient-spread",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:43:27.907146Z",
     "start_time": "2021-03-22T08:43:27.893146Z"
    }
   },
   "outputs": [],
   "source": [
    "# 첫번째, 0 이아닌 데이터 추출\n",
    "data2 = np.array([1, 5, 1, 4, 3, 2, 5, 6, 3, 2, 7, 8, 1])\n",
    "\n",
    "# 두번째, 행 위치와 열 위치를 각각 array로 생성\n",
    "row_pos = np.array([0, 0, 1, 1, 1, 1, 1, 2, 2, 3, 4, 4, 5])\n",
    "col_pos = np.array([2, 5, 0, 1, 3, 4, 5, 1, 3, 0, 3, 5, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "sublime-cooler",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:45:10.370000Z",
     "start_time": "2021-03-22T08:45:10.358011Z"
    }
   },
   "outputs": [],
   "source": [
    "# COO 형식\n",
    "sparse_coo = sparse.coo_matrix((data2, (row_pos, col_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "twelve-shannon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:48:44.343312Z",
     "start_time": "2021-03-22T08:48:44.329313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COO 변환된 데이터가 제대로 되었는지 다시 Dense로 출력 확인\n",
      "[[0 0 1 0 0 5]\n",
      " [1 4 0 3 2 5]\n",
      " [0 6 0 3 0 0]\n",
      " [2 0 0 0 0 0]\n",
      " [0 0 0 7 0 8]\n",
      " [1 0 0 0 0 0]]\n",
      "CSR 변환된 데이터가 제대로 되었는지 다시 Dense로 출력 확인\n",
      "[[0 0 1 0 0 5]\n",
      " [1 4 0 3 2 5]\n",
      " [0 6 0 3 0 0]\n",
      " [2 0 0 0 0 0]\n",
      " [0 0 0 7 0 8]\n",
      " [1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# 세번째\n",
    "# row_pos = np.array([0, 0, 1, 1, 1, 1, 1, 2, 2, 3, 4, 4, 5]) # 배열인덱스를 확인\n",
    "#             index : 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,11,12\n",
    "# 숫자가 변하는 곳의 인덱스만 따로 모아 배열로 만듬 - 13은 마지막자료 의미\n",
    "row_pos_ind = np.array([0, 2, 7, 9, 10, 12, 13,])\n",
    "\n",
    "# CSR형식으로 변환\n",
    "sparse_csr = sparse.csr_matrix((data2, col_pos, row_pos_ind))\n",
    "print('COO 변환된 데이터가 제대로 되었는지 다시 Dense로 출력 확인')\n",
    "print(sparse_coo.toarray())\n",
    "print('CSR 변환된 데이터가 제대로 되었는지 다시 Dense로 출력 확인')\n",
    "print(sparse_csr.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-workshop",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
